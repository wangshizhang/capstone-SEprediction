{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "83bd1b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "import torchvision.datasets as dset\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import argparse\n",
    "import torch\n",
    "# import torch.tensor as tensor\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from torchvision import models\n",
    "#from resnet import resnet50\n",
    "#from res2net import res2net50_48w_2s,res2net50_26w_8s,res2net50\n",
    "\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "#from resnet import resnet50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2b52663",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor(x):\n",
    "    return torch.tensor(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41d6e796",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('DataSet_2021_8_5_filter_combine_normalize.pkl', 'rb') as f:\n",
    "    X_train,y_train,X_val,y_val,X_test,y_test,y_max = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "913b14d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1352314, 47) (1352314, 2) (29142, 47) (29142, 2) (128232, 47) (128232, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,y_train.shape,X_val.shape,y_val.shape,X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3719a26b",
   "metadata": {},
   "source": [
    "### Dataset process for label training - split original dataset and transfer labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b647fb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_transfer(labels,transfer_pairs):\n",
    "    for pair in transfer_pairs:\n",
    "        print(labels==pair[0])\n",
    "        labels[labels==pair[0]] = pair[1]\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52c9fd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def y2label(y_ori,y_max):\n",
    "    labels = np.zeros(y_ori.shape).astype(np.int32)+3\n",
    "    \n",
    "    labels[y_ori*y_max <= 2250] = 2\n",
    "    labels[y_ori*y_max <= 1850] = 1\n",
    "    labels[y_ori*y_max <= 1350] = 0\n",
    "    \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "373b9bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[:,0:34]\n",
    "y_train = y_train[:,0]\n",
    "X_val = X_val[:,0:34]\n",
    "y_val = y_val[:,0]\n",
    "X_test = X_test[:,0:34]\n",
    "y_test = y_test[:,0]\n",
    "ylabel_train = y2label(y_train,y_max[0])\n",
    "ylabel_val = y2label(y_val,y_max[0])\n",
    "ylabel_test = y2label(y_test,y_max[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e005fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = [sum(ylabel_train == 0),sum(ylabel_train == 1),sum(ylabel_train == 2),sum(ylabel_train == 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f412932f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 4 artists>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(range(len(counts)),counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d16f53b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Train_Dataset(Dataset):\n",
    "    def __init__(self, path=\"DataSet_2021_8_5_filter_combine_normalize.pkl\",transform=None, target_transform=None):\n",
    "        \n",
    "        with open('DataSet_2021_8_5_filter_combine_normalize.pkl', 'rb') as f:\n",
    "            X_train,y_train,X_val,y_val,X_test,y_test,y_max = pickle.load(f)\n",
    "        \n",
    "        self.X_train = X_train[:,0:34]\n",
    "        self.y_train = y_train[:,0]\n",
    "        \n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X_train.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        #image = torchvision.transforms.functional.to_tensor(np.array(image.resize((240,320),Image.BILINEAR)))\n",
    "        #label = tensor(self.label2vec(label))\n",
    "        \n",
    "        x_train = tensor(self.X_train[idx,:])\n",
    "        label = tensor(self.y_train[idx])\n",
    "    \n",
    "        return x_train,label\n",
    "\n",
    "class Val_Dataset(Dataset):\n",
    "    def __init__(self, path=\"DataSet_2021_8_5_filter_combine_normalize.pkl\",transform=None, target_transform=None):\n",
    "        \n",
    "        with open('DataSet_2021_8_5_filter_combine_normalize.pkl', 'rb') as f:\n",
    "            X_train,y_train,X_val,y_val,X_test,y_test,y_max = pickle.load(f)\n",
    "        \n",
    "        self.X_val = X_val[:,0:34]\n",
    "        self.y_val = y_val[:,0]\n",
    "        \n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X_val.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        #image = torchvision.transforms.functional.to_tensor(np.array(image.resize((240,320),Image.BILINEAR)))\n",
    "        #label = tensor(self.label2vec(label))\n",
    "        \n",
    "        x_val = tensor(self.X_val[idx,:])\n",
    "        label = tensor(self.y_val[idx])\n",
    "    \n",
    "        return x_val,label\n",
    "\n",
    "class Test_Dataset(Dataset):\n",
    "    def __init__(self, path=\"DataSet_2021_8_5_filter_combine_normalize.pkl\",transform=None, target_transform=None):\n",
    "        \n",
    "        with open('DataSet_2021_8_5_filter_combine_normalize.pkl', 'rb') as f:\n",
    "            X_train,y_train,X_val,y_val,X_test,y_test,y_max = pickle.load(f)\n",
    "        \n",
    "        self.X_test = X_test[:,0:34]\n",
    "        self.y_test = y_test[:,0]\n",
    "        \n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X_test.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        #image = torchvision.transforms.functional.to_tensor(np.array(image.resize((240,320),Image.BILINEAR)))\n",
    "        #label = tensor(self.label2vec(label))\n",
    "        \n",
    "        x_test = tensor(self.X_test[idx,:])\n",
    "        label = tensor(self.y_test[idx])\n",
    "    \n",
    "        return x_test,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be607440",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Train_Label_Dataset(Dataset):\n",
    "    def __init__(self, path=\"DataSet_2021_8_5_filter_combine_normalize.pkl\",transform=None, target_transform=None):\n",
    "        \n",
    "        with open('DataSet_2021_8_5_filter_combine_normalize.pkl', 'rb') as f:\n",
    "            X_train,y_train,X_val,y_val,X_test,y_test,y_max = pickle.load(f)\n",
    "        \n",
    "        self.X_train = X_train[:,0:34]\n",
    "        self.y_train = y2label(y_train[:,0],y_max[0])\n",
    "        \n",
    "        \n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X_train.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        #image = torchvision.transforms.functional.to_tensor(np.array(image.resize((240,320),Image.BILINEAR)))\n",
    "        #label = tensor(self.label2vec(label))\n",
    "        \n",
    "        x_train = tensor(self.X_train[idx,:])\n",
    "        label = tensor(self.y_train[idx])\n",
    "    \n",
    "        return x_train,label\n",
    "\n",
    "class Val_Label_Dataset(Dataset):\n",
    "    def __init__(self, path=\"DataSet_2021_8_5_filter_combine_normalize.pkl\",transform=None, target_transform=None):\n",
    "        \n",
    "        with open('DataSet_2021_8_5_filter_combine_normalize.pkl', 'rb') as f:\n",
    "            X_train,y_train,X_val,y_val,X_test,y_test,y_max = pickle.load(f)\n",
    "        \n",
    "        self.X_val = X_val[:,0:34]\n",
    "        self.y_val = y2label(y_val[:,0],y_max[0])\n",
    "        \n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X_val.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        #image = torchvision.transforms.functional.to_tensor(np.array(image.resize((240,320),Image.BILINEAR)))\n",
    "        #label = tensor(self.label2vec(label))\n",
    "        \n",
    "        x_val = tensor(self.X_val[idx,:])\n",
    "        label = tensor(self.y_val[idx])\n",
    "    \n",
    "        return x_val,label\n",
    "\n",
    "class Test_Label_Dataset(Dataset):\n",
    "    def __init__(self, path=\"DataSet_2021_8_5_filter_combine_normalize.pkl\",transform=None, target_transform=None):\n",
    "        \n",
    "        with open('DataSet_2021_8_5_filter_combine_normalize.pkl', 'rb') as f:\n",
    "            X_train,y_train,X_val,y_val,X_test,y_test,y_max = pickle.load(f)\n",
    "        \n",
    "        self.X_test = X_test[:,0:34]\n",
    "        self.y_test = y2label(y_test[:,0],y_max[0])\n",
    "        \n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X_test.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        #image = torchvision.transforms.functional.to_tensor(np.array(image.resize((240,320),Image.BILINEAR)))\n",
    "        #label = tensor(self.label2vec(label))\n",
    "        \n",
    "        x_test = tensor(self.X_test[idx,:])\n",
    "        label = tensor(self.y_test[idx])\n",
    "    \n",
    "        return x_test,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "843a6bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(train_loader, classifier, criterion, optimizer,show_interval = 3000):\n",
    "    classifier.train()\n",
    "    loss_ = 0.0\n",
    "    losses = []\n",
    "    acc = []\n",
    "    # f1_list = []\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        labels = torch.tensor(np.array(labels))\n",
    "        images, labels = images.to(torch.float32).to(device), labels.to(torch.int64).to(device)\n",
    "        \n",
    "        logits = classifier(images)\n",
    "        loss = criterion(logits,labels)\n",
    "        loss = loss.requires_grad_()\n",
    "        \n",
    "        if i % show_interval == 0:\n",
    "            print(i*args.batch_size)\n",
    "            # acc_new = acc_cal(logits.detach(),labels.numpy())\n",
    "            acc_new = acc_f1_cal_multi(logits.detach(),labels.numpy())\n",
    "            acc += np.mean(acc_new)\n",
    "            # f1_list += [f1]\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.detach())\n",
    "        \n",
    "    return torch.stack(losses).mean().item(),np.mean(acc)\n",
    "\n",
    "def train_classifier_cnn(train_loader, classifier, criterion, optimizer,show_interval = 3000):\n",
    "    classifier.train()\n",
    "    loss_ = 0.0\n",
    "    losses = []\n",
    "    acc = []\n",
    "    # f1_list = []\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        labels = torch.tensor(np.array(labels))\n",
    "        images, labels = images.to(torch.float32).to(device), labels.to(torch.int64).to(device)\n",
    "        \n",
    "        images = images.reshape((images.shape[0],1,images.shape[1]))\n",
    "        logits = classifier(images)\n",
    "        logits = logits.reshape((logits.shape[0],logits.shape[2]))\n",
    "        loss = criterion(logits,labels)\n",
    "        loss = loss.requires_grad_()\n",
    "        \n",
    "        if i % show_interval == 0:\n",
    "            print(i*args.batch_size)\n",
    "            # acc_new = acc_cal(logits.detach(),labels.numpy())\n",
    "            # acc_new,_ = acc_f1_cal_multi(logits.detach(),labels.numpy())\n",
    "            # acc += np.mean(acc_new)\n",
    "            # f1_list += [f1]\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.detach())\n",
    "        \n",
    "    return torch.stack(losses).mean().item()\n",
    "    \n",
    "def test_classifier(test_loader, classifier, criterion, print_ind_classes=True):\n",
    "    classifier.eval()\n",
    "    losses = []\n",
    "    acc = []\n",
    "    logits_all = np.zeros((0,4))\n",
    "    labels_all = np.zeros((0))\n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels) in enumerate(test_loader):\n",
    "            labels = torch.tensor(np.array(labels))\n",
    "            images, labels = images.to(torch.float32).to(device), labels.to(torch.int64).to(device)\n",
    "\n",
    "            logits = classifier(images)\n",
    "            # print(logits.shape,labels.shape)\n",
    "            logits_all = np.vstack((logits_all,logits.detach()))\n",
    "            labels_all = np.hstack((labels_all,labels))\n",
    "            # acc_new = acc_cal(logits,labels)\n",
    "            # acc += [acc_new]\n",
    "            \n",
    "            loss = criterion(logits,labels)\n",
    "            losses.append(loss.detach())\n",
    "        \n",
    "        test_loss = torch.stack(losses).mean().item()\n",
    "    return test_loss,acc_f1_cal_multi(logits_all,labels_all)\n",
    "\n",
    "def test_classifier_cnn(test_loader, classifier, criterion, print_ind_classes=True):\n",
    "    classifier.eval()\n",
    "    losses = []\n",
    "    acc = []\n",
    "    logits_all = np.zeros((0,4))\n",
    "    labels_all = np.zeros((0))\n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels) in enumerate(test_loader):\n",
    "            labels = torch.tensor(np.array(labels))\n",
    "            images, labels = images.to(torch.float32).to(device), labels.to(torch.int64).to(device)\n",
    "\n",
    "            images = images.reshape((images.shape[0],1,images.shape[1]))\n",
    "            logits = classifier(images)\n",
    "            logits = logits.reshape((logits.shape[0],logits.shape[2]))\n",
    "            # print(logits.shape,labels.shape)\n",
    "            logits_all = np.vstack((logits_all,logits.detach().cpu()))\n",
    "            labels_all = np.hstack((labels_all,labels.cpu()))\n",
    "            # acc_new = acc_cal(logits,labels)\n",
    "            # acc += [acc_new]\n",
    "            \n",
    "            loss = criterion(logits,labels)\n",
    "            losses.append(loss.detach())\n",
    "        \n",
    "        test_loss = torch.stack(losses).mean().item()\n",
    "    return test_loss,acc_f1_cal_multi(logits_all,labels_all)\n",
    "\n",
    "def acc_cal(logits,labels,show = False):\n",
    "    pred_labels = np.argmax(logits,1)\n",
    "    pred_flags = pred_labels == labels\n",
    "    acc = np.sum(pred_flags)/pred_labels.shape[0]\n",
    "    if(show):\n",
    "        print(pred_labels)\n",
    "    return acc\n",
    "\n",
    "def acc_f1_cal_multi(logits,labels):\n",
    "    # print(logits.shape,labels.shape)\n",
    "    labels = labels.astype(np.int32)\n",
    "    logits = np.argmax(logits,1)\n",
    "    f1 = f1_score(logits,labels,average=None)\n",
    "    label_set = set([0,1,2,3])\n",
    "    acc = np.zeros((len(label_set)))\n",
    "    for label in label_set:\n",
    "        index = labels == label\n",
    "        print(label,np.sum(index))\n",
    "        acc[label] = np.sum(logits[index] == labels[index])/(len(labels[index]))\n",
    "    return acc,f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbf8ccf",
   "metadata": {},
   "source": [
    "### Hyper Parameters Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9f47ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class paras():\n",
    "    def __init__(self):\n",
    "        self.batch_size = None\n",
    "        self.classes = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9a2bc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = paras()\n",
    "args.batch_size = 128\n",
    "#args.classes = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e1e289",
   "metadata": {},
   "source": [
    "### Dataloader Initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ddc90545",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Train_Dataset()\n",
    "val_dataset = Val_Dataset()\n",
    "test_dataset = Test_Dataset()\n",
    "\n",
    "train_label_dataset = Train_Label_Dataset()\n",
    "val_label_dataset = Val_Label_Dataset()\n",
    "test_label_dataset = Test_Label_Dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4831a977",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=False)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=args.batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=args.batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6ea4411",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label_dataloader = DataLoader(train_label_dataset, batch_size=args.batch_size, shuffle=False)\n",
    "val_label_dataloader = DataLoader(val_label_dataset, batch_size=args.batch_size, shuffle=True)\n",
    "test_label_dataloader = DataLoader(test_label_dataset, batch_size=args.batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663ccedc",
   "metadata": {},
   "source": [
    "### Model Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19ebfe2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "04ff3268",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_BN(nn.Module):\n",
    "    def __init__(self, input_size,output_size):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 2*input_size)\n",
    "        nn.init.kaiming_normal_(self.fc1.weight)\n",
    "        self.BN1 = nn.BatchNorm1d(2*input_size)\n",
    "        \n",
    "        self.fc2 = nn.Linear(2*input_size, 4*input_size)\n",
    "        nn.init.kaiming_normal_(self.fc2.weight)\n",
    "        self.BN2 = nn.BatchNorm1d(4*input_size)\n",
    "        \n",
    "        \n",
    "        self.fc3 = nn.Linear(4*input_size, input_size)\n",
    "        nn.init.kaiming_normal_(self.fc3.weight)\n",
    "        self.BN3 = nn.BatchNorm1d(input_size)\n",
    "        \n",
    "        self.fc4 = nn.Linear(input_size, 8)\n",
    "        nn.init.kaiming_normal_(self.fc4.weight)\n",
    "        self.BN4 = nn.BatchNorm1d(8)\n",
    "        \n",
    "        self.fc5 = nn.Linear(8, output_size)\n",
    "        nn.init.kaiming_normal_(self.fc5.weight)\n",
    "        \n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        # forward always defines connectivity\n",
    "        #x = flatten(x)\n",
    "        #scores = self.fc2(F.relu(self.fc1(x)))\n",
    "        #print(x.shape)\n",
    "        x = torch.tensor(x).to(torch.float32)\n",
    "        x = self.BN1(F.relu(self.fc1(x)))\n",
    "        x = self.BN2(F.relu(self.fc2(x)))\n",
    "        x = self.BN3(F.relu(self.fc3(x)))\n",
    "        x = self.BN4(F.relu(self.fc4(x)))\n",
    "        x = F.relu(self.fc5(x))\n",
    "        \n",
    "        return x\n",
    "    \n",
    "class DeepMLP(nn.Module):\n",
    "    def __init__(self, input_size,output_size):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 2*input_size)\n",
    "        nn.init.kaiming_normal_(self.fc1.weight)\n",
    "        \n",
    "        self.fc2 = nn.Linear(2*input_size, 4*input_size)\n",
    "        nn.init.kaiming_normal_(self.fc2.weight)\n",
    "        \n",
    "        self.fc3 = nn.Linear(4*input_size, 8*input_size)\n",
    "        nn.init.kaiming_normal_(self.fc3.weight)\n",
    "        \n",
    "        self.fc4 = nn.Linear(8*input_size, input_size)\n",
    "        nn.init.kaiming_normal_(self.fc4.weight)\n",
    "        \n",
    "        self.fc5 = nn.Linear(input_size, input_size//4)\n",
    "        nn.init.kaiming_normal_(self.fc5.weight)\n",
    "        \n",
    "        self.fc6 = nn.Linear(input_size//4, output_size)\n",
    "        nn.init.kaiming_normal_(self.fc6.weight)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        # forward always defines connectivity\n",
    "        #x = flatten(x)\n",
    "        #scores = self.fc2(F.relu(self.fc1(x)))\n",
    "        #print(x.shape)\n",
    "        x0 = torch.tensor(x).to(torch.float32)\n",
    "        x = nn.LeakyReLU(0.3)(self.fc1(x0))\n",
    "        x = nn.LeakyReLU(0.2)(self.fc2(x))\n",
    "        x = nn.LeakyReLU(0.18)(self.fc3(x))\n",
    "        \n",
    "        x = nn.LeakyReLU(0.15)(self.fc4(x))+x0 #residual here\n",
    "        \n",
    "        x = nn.LeakyReLU(0.1)(self.fc5(x))\n",
    "        x = torch.sigmoid(self.fc6(x))\n",
    "        \n",
    "        return x    \n",
    "class TestMLP(nn.Module):\n",
    "    def __init__(self, input_size,output_size):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 2*input_size)\n",
    "        nn.init.kaiming_normal_(self.fc1.weight)\n",
    "        \n",
    "        self.fc2 = nn.Linear(2*input_size, 4*input_size)\n",
    "        nn.init.kaiming_normal_(self.fc2.weight)\n",
    "        \n",
    "        self.fc3 = nn.Linear(4*input_size, input_size)\n",
    "        nn.init.kaiming_normal_(self.fc3.weight)\n",
    "        \n",
    "        self.fc4 = nn.Linear(input_size, 8)\n",
    "        nn.init.kaiming_normal_(self.fc4.weight)\n",
    "        \n",
    "        self.fc5 = nn.Linear(8, output_size)\n",
    "        nn.init.kaiming_normal_(self.fc5.weight)\n",
    "        \n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        # forward always defines connectivity\n",
    "        #x = flatten(x)\n",
    "        #scores = self.fc2(F.relu(self.fc1(x)))\n",
    "        #print(x.shape)\n",
    "        x = torch.tensor(x).to(torch.float32)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = F.relu(self.fc5(x))\n",
    "        \n",
    "        return x\n",
    "\n",
    "class MLP1DCNN(nn.Module):\n",
    "    # 两层卷积 + MLP\n",
    "    def __init__(self, input_size,output_size):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(1,1,5,padding = 1)\n",
    "        self.conv2 = nn.Conv1d(1,1,3)\n",
    "        self.conv3 = nn.Conv1d(1,1,7,padding = 2)\n",
    "        self.conv4 = nn.Conv1d(3,1,5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(28, 2*input_size)\n",
    "        nn.init.kaiming_normal_(self.fc1.weight)\n",
    "        \n",
    "        self.fc2 = nn.Linear(2*input_size, 4*input_size)\n",
    "        nn.init.kaiming_normal_(self.fc2.weight)\n",
    "        \n",
    "        self.fc3 = nn.Linear(4*input_size, input_size)\n",
    "        nn.init.kaiming_normal_(self.fc3.weight)\n",
    "        \n",
    "        self.fc4 = nn.Linear(input_size, 8)\n",
    "        nn.init.kaiming_normal_(self.fc4.weight)\n",
    "        \n",
    "        self.fc5 = nn.Linear(8, output_size)\n",
    "        nn.init.kaiming_normal_(self.fc5.weight)\n",
    "        \n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        # forward always defines connectivity\n",
    "        #x = flatten(x)\n",
    "        #scores = self.fc2(F.relu(self.fc1(x)))\n",
    "        #print(x.shape)\n",
    "        x = torch.tensor(x).to(torch.float32)\n",
    "\n",
    "        x1 = self.conv1(x)\n",
    "        x2 = self.conv2(x)\n",
    "        x3 = self.conv3(x)\n",
    "        x_sum = torch.cat((x1,x2,x3),axis = 1)\n",
    "        x = self.conv4(x_sum)\n",
    "#         x = self.conv2(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "\n",
    "        x = F.relu(self.fc5(x))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90afd88",
   "metadata": {},
   "source": [
    "model = DeepMLP(X_train.shape[1],1)\n",
    "classifier = model.to(device)\n",
    "\n",
    "criterion = torch.nn.L1Loss()\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "daaeffd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_classifier = torch.load(\"label_classifier.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "d446a253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label classifier model\n",
    "model = MLP1DCNN(X_train.shape[1],4)\n",
    "classifier = model.to(device)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afad21e5",
   "metadata": {},
   "source": [
    "### Optimizer Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "869f44dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "moment = 0.8\n",
    "epoch_sum = 0\n",
    "\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, classifier.parameters()), lr=lr)\n",
    "# optimizer = torch.optim.SGD(filter(lambda p: p.requires_grad, classifier.parameters()), lr=lr, momentum=moment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "74f2890e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if epoch_sum == 0:\n",
    "    train_loss_list = []\n",
    "    val_loss_list = []\n",
    "    val_f1_list = []\n",
    "    time_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b84e79e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch number 0\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:143: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384000\n",
      "768000\n",
      "1152000\n",
      "Loss for Training on Epoch 0 is 1.386067271232605\n",
      "Time for epoch 0 is 94.47874712944031\n",
      "0 4011\n",
      "1 10114\n",
      "2 9061\n",
      "3 5956\n",
      "Evaluating classifier\n",
      "Loss for validation on Epoch0 is (1.3862950801849365, (array([0.99975069, 0.        , 0.        , 0.        ]), array([0.24191602, 0.        , 0.        , 0.        ])))\n",
      "Starting epoch number 1\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:143: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    }
   ],
   "source": [
    "# Train the Label Classifier Model\n",
    "NUM_EPOCHS = 15\n",
    "TEST_FREQUENCY = 1\n",
    "time_start = time.time()\n",
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    time_epoch_start = time.time()\n",
    "    print(\"Starting epoch number \" + str(epoch_sum))\n",
    "    train_loss = train_classifier_cnn(train_label_dataloader, classifier, criterion, optimizer)\n",
    "    train_loss_list += [train_loss]\n",
    "    print(\"Loss for Training on Epoch \" +str(epoch_sum) + \" is \"+ str(train_loss))\n",
    "    \n",
    "    #plt.plot(train_loss_list)\n",
    "    time_epoch_end = time.time()\n",
    "    time_one_epoch = time_epoch_end - time_epoch_start\n",
    "    time_list += [time_one_epoch]\n",
    "    print(\"Time for epoch {} is {}\".format(epoch_sum,time_one_epoch))\n",
    "    \n",
    "    \n",
    "    if(epoch_sum%TEST_FREQUENCY==0):\n",
    "        val_loss= test_classifier_cnn(val_label_dataloader, classifier, criterion)\n",
    "        val_loss_list += [val_loss]\n",
    "        print('Evaluating classifier')\n",
    "        print(\"Loss for validation on Epoch\"+str(epoch_sum)+\" is \"+str(val_loss))\n",
    "    \n",
    "    epoch_sum += 1\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "c69a7607",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,\"label_classifier_mod.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "c2c33490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Loss Curve')"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss_list,label=\"Train Loss\")\n",
    "plt.plot(val_loss_list1,label=\"Validation Loss\")\n",
    "\n",
    "plt.legend()\n",
    "plt.title(\"Loss Curve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d61f3471",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(classifier,\"Only_MLP_\"+\"epoch{}.pt\".format(epoch_sum))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb69160",
   "metadata": {},
   "source": [
    "### Predict with test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8d2c7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_se(model, X_test, y_test, dataset_SE_max, plot=True):\n",
    "    print(\"[INFO] predicting...\")\n",
    "    X_test = torch.tensor(X_test).to(device)\n",
    "    preds = model.forward(X_test)\n",
    "    preds = preds.cpu().detach().numpy().flatten()\n",
    "    y_test = y_test.flatten()\n",
    "    diff = abs(preds-y_test)*dataset_SE_max\n",
    "    # choose how many bins you want here\n",
    "    num_bins = 30\n",
    "    # use the histogram function to bin the data\n",
    "    counts, bin_edges = np.histogram(diff, bins=num_bins)\n",
    "    # now find the cdf\n",
    "    cdf = np.cumsum(counts)\n",
    "    # and finally plot the cdf\n",
    "    if plot:\n",
    "        plt.plot(bin_edges[1:], cdf)\n",
    "        plt.xlabel('Absolute Error (Mbit/Number)')\n",
    "        plt.ylabel('Count')\n",
    "        plt.title('Error CDF')\n",
    "        plt.show()\n",
    "    diff_percen = abs(preds-y_test)/y_test\n",
    "    mean = np.mean(abs(diff))\n",
    "    std = np.std(diff)\n",
    "    print(\"[INFO] error mean: {:.3f}, std: {:.3f}\".format(mean, std))\n",
    "    mean = np.mean(abs(diff_percen))\n",
    "    std = np.std(diff_percen)\n",
    "    print(\"[INFO] percentage error mean: {:.3f}, std: {:.3f}\" .format(mean, std))\n",
    "    axis_lim = y_test.mean()*dataset_SE_max*2\n",
    "    # mean absolute percentage error by sections\n",
    "    diff_with_y = np.hstack((y_test[:,np.newaxis]*dataset_SE_max, diff_percen[:,np.newaxis]))\n",
    "    sort_indices = np.argsort(diff_with_y[:,0])\n",
    "    diff_with_y = diff_with_y[sort_indices,:]\n",
    "    mape_sections = np.array([1000, 1500, 2500, np.iinfo(int).max])\n",
    "    mape_sections_mean = np.empty(len(mape_sections))\n",
    "    idx_section = 0\n",
    "    diff_id_section = 0\n",
    "    for i in range(len(diff_with_y)):\n",
    "        if diff_with_y[i,0]>mape_sections[idx_section] or i == len(diff_with_y)-1:\n",
    "            mape_sections_mean[idx_section] = np.mean(diff_with_y[diff_id_section:i,1])\n",
    "            diff_id_section = i\n",
    "            idx_section = idx_section + 1\n",
    "    print(\"[INFO] MAPE by sections: \", np.around(mape_sections_mean, decimals=2))\n",
    "    if plot:\n",
    "        plt.figure()\n",
    "        plt.plot(preds.flatten()*dataset_SE_max, y_test*dataset_SE_max, '.')\n",
    "        plt.plot([0, axis_lim], [0, axis_lim])\n",
    "        plt.axis([0, axis_lim, 0, axis_lim])\n",
    "        plt.xlabel('Prediction (Mbit/Number)')\n",
    "        plt.ylabel('Ground Truth (Mbit/Number)')\n",
    "        plt.title('Spectral Efficiency')\n",
    "        plt.show()\n",
    "\n",
    "def VisPredict(model,plotOn,X_train,y_train,X_val,y_val,X_test,y_test,dataset_SE_max):\n",
    "    # make predictions on the testing data\n",
    "    predict_se(model, X_train, y_train, dataset_SE_max, plotOn)\n",
    "    predict_se(model, X_val, y_val, dataset_SE_max, plotOn)\n",
    "    predict_se(model, X_test, y_test, dataset_SE_max, plotOn)\n",
    "    if plotOn:\n",
    "        dot_img_file = 'figures/model_1.png'\n",
    "        #tf.keras.utils.plot_model(model, to_file=dot_img_file, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db89d68a",
   "metadata": {},
   "source": [
    "### Predict Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f719b3c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-9da14173e49b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty_cache\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mVisPredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_max\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache ()\n",
    "VisPredict(model,True,X_train,y_train,X_val,y_val,X_test,y_test,y_max[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a6773c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee26ca7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfbf804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f6bbbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d5146f3029d6424cdc6ef191d54c22462012605892d6b80a61222a44e90cce02"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
